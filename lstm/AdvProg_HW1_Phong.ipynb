{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvProg HW1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8IMVCaOJKoj",
        "colab_type": "text"
      },
      "source": [
        "Using LSTM to generate sin function. \n",
        "\n",
        "Set up: \n",
        "\n",
        "- Training : using 50 numbers as X to generate the 51st number as y and so on. \n",
        "- Test : test on 20 numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQMxd_dVJO5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVxEiuCxKyXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining model: \n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,input_dim,out_dim,hidden_dim):\n",
        "      super(LSTM,self).__init__()\n",
        "      self.input_dim = input_dim\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.out_dim = out_dim\n",
        "      self.LSTM = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional = False, )\n",
        "      self.ln = nn.Linear(1*hidden_dim, self.out_dim)\n",
        "      self.ln2 = nn.Linear(self.out_dim, self.out_dim)\n",
        "    def forward (self, inp):\n",
        "      output,_ = self.LSTM(inp)\n",
        "      x = torch.tanh(self.ln(output))\n",
        "      x = self.ln2(x)\n",
        "      return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6Mh76LPtfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(50,1,20)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqT_uwChP81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "02fc0453-9b1d-4fa8-a7c3-5d09f0bc20f9"
      },
      "source": [
        "model.double().to('cuda')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (LSTM): LSTM(50, 20, batch_first=True)\n",
              "  (ln): Linear(in_features=20, out_features=1, bias=True)\n",
              "  (ln2): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqE14JfoaI96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.08)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upo9fhh8QQnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate training and testing data: \n",
        "def train_function(X, function ='sin'):\n",
        "  if function == 'cos':\n",
        "    return np.cos(X)\n",
        "  else: \n",
        "    return np.sin(X)\n",
        "\n",
        "def split_sequence(sequence, n_steps):\n",
        "        X, y = list(), list()\n",
        "        for i in range(len(sequence)):\n",
        "                end_ix = i + n_steps\n",
        "                if end_ix > len(sequence)-1:\n",
        "                        break\n",
        "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "                X.append(seq_x)\n",
        "                y.append(seq_y)\n",
        "        # X = np.array(X).astype(np.float32)\n",
        "        # X = torch.from_numpy(X)\n",
        "        # X = X.unsqueeze(dim=0)\n",
        "        # y = np.array(y).astype(np.float32)\n",
        "        # y = torch.from_numpy(y)\n",
        "        X = torch.tensor(X)\n",
        "        X = X.unsqueeze(dim=0)\n",
        "        y = torch.tensor(y).reshape(-1,1)\n",
        "        return X,y\n",
        "\n",
        "#define input sequence: \n",
        "xaxis = np.arange(-100*np.pi, 100*np.pi, 0.1)\n",
        "train_seq = train_function(xaxis)\n",
        "n_steps = 50\n",
        "X, y = split_sequence(train_seq, n_steps)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJfsADPUszEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "236357d2-1bcb-49bc-ac64-c1f2306bd9c2"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6234, 50]), torch.Size([6234, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkU344iRZ1jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "6b52da04-1253-4951-b7fe-1bed8e3948d4"
      },
      "source": [
        "#training with 1000 epochs: \n",
        "\n",
        "epochs = 200\n",
        "\n",
        "for i in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  y_pred = model(X.to('cuda'))\n",
        "  single_loss = loss_function(y_pred[0], y.to('cuda'))\n",
        "  single_loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  if i%25 == 1:\n",
        "      print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
        "\n",
        "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:   1 loss: 0.41483101\n",
            "epoch:  26 loss: 0.00497311\n",
            "epoch:  51 loss: 0.00100262\n",
            "epoch:  76 loss: 0.00041769\n",
            "epoch: 101 loss: 0.00024795\n",
            "epoch: 126 loss: 0.00014392\n",
            "epoch: 151 loss: 0.00009798\n",
            "epoch: 176 loss: 0.00007921\n",
            "epoch: 199 loss: 0.0000553740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF3Z24XPZM8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}