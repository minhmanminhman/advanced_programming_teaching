{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "These files do following steps:\n",
    "\n",
    "* 1. We need to create a object `RegressionColumnarDataset`: in example **Traing a classifier** on PyTorch home page tutorial, we download data using PyTorch functions and then load the data into dataloader directly. The downloaded data have already been wrapped in a class called `torch.utils.data.Dataset`. Here, we use a dataset from Kaggle so we need to create a class to wrap that dataset.\n",
    "\n",
    "* 2. After creating `RegressionColumnarDataset`, use function `setup_dataloader` to put our dataset into data loader.\n",
    "\n",
    "* 3. In this level, we use a simple way to write Neural Network structure and `training_loop`. The `training_loop` trains the model and print some basic information of the training process.\n",
    "\n",
    "In level 2, we will write a Network structure in a different way and write a `training_loop_2` with ability to plot the tracking loss and save best model in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:12.848313Z",
     "start_time": "2020-06-13T06:59:12.829367Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../seminar_1')\n",
    "import pandas as pd\n",
    "from utils.helper_functions import save_pickle, load_pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import copy\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RegressionColumnarDataset(Data.Dataset):\n",
    "    \"\"\"\n",
    "    Object Dataset in PyTorch to store dataset before loading into DataLoader\n",
    "    \"\"\"\n",
    "    def __init__(self, df_transformed, target):\n",
    "        self.data = df_transformed.copy().values.astype(np.float32)\n",
    "        # Select target\n",
    "        self.target = target.values.astype(np.float32)\n",
    "        self.n_feature = self.data.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.data[idx], self.target[idx]]\n",
    "\n",
    "def setup_dataloader(df, mapper, batch_size=256, shuffle=True, num_workers=0):\n",
    "    \"\"\"\n",
    "    Convert preprocessed DataFrame (with target column 'price') into DataLoader\n",
    "    \"\"\"\n",
    "    df_transformed = mapper.transform(df)\n",
    "    target = df['price'].copy() / 1e6\n",
    "    df_dataset = RegressionColumnarDataset(df_transformed, target)\n",
    "    dataloader = Data.DataLoader(df_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
    "    return dataloader\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    \"\"\"\n",
    "    Convert a Pytorch tensor to numpy\n",
    "    \"\"\"\n",
    "    return tensor.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:24.379104Z",
     "start_time": "2020-06-13T06:59:24.063783Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "mapper = load_pickle('model/mapper.pkl')\n",
    "\n",
    "traindl = setup_dataloader(train, mapper)\n",
    "testdl = setup_dataloader(test, mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T02:06:05.375350Z",
     "start_time": "2020-06-12T02:06:05.363384Z"
    }
   },
   "source": [
    "# Neural Network Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:25.131080Z",
     "start_time": "2020-06-13T06:59:25.111136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weight initial\n",
    "def customize_weight_init(x):\n",
    "    \"\"\"\n",
    "    Use Xavier method to initialize weight\n",
    "    \"\"\"\n",
    "    classname = x.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(x.weight)\n",
    "        nn.init.constant_(x.bias, 0)\n",
    "        \n",
    "    if classname.find('BatchNorm') != -1:\n",
    "        nn.init.constant_(x.weight, 1)\n",
    "        nn.init.constant_(x.bias, 0)\n",
    "\n",
    "# Define model\n",
    "class NNet_model_1(nn.Module):\n",
    "    def __init__(self, input_dim, layer1, layer2, n_output=1):\n",
    "        '''\n",
    "        A class that defines the neural network structure\n",
    "        \n",
    "        Params:\n",
    "        input_dim: number of features from the dataset\n",
    "        layer1 : num of neurons in layer 1\n",
    "        layer2: num of neurons in layer 2\n",
    "        \n",
    "        output: \n",
    "        an object that holds the model structure (can be called as a function)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(layer1),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(layer1, layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(layer2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(layer2, n_output)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:26.655503Z",
     "start_time": "2020-06-13T06:59:26.637554Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NNet_model_1(traindl.dataset.n_feature, 128, 32)\n",
    "model.apply(customize_weight_init)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay= 0.1)\n",
    "loss_function = nn.MSELoss(reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:28.070930Z",
     "start_time": "2020-06-13T06:59:28.057965Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_loop(traindl, testdl, model, optimizer, loss_function, \n",
    "               seed=0, epoches=5, save_folder='model', verbose=True):\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    if verbose: print('Training on: ', device)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Some setup\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epoches): \n",
    "        # Tracking loss\n",
    "        train_loss = np.array([])\n",
    "        test_loss = np.array([])\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        for x, y in iter(traindl):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x).to(device)\n",
    "            loss = loss_function(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track train loss\n",
    "            train_loss  = np.concatenate((train_loss, loss.item()), axis=None)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        for x, y in iter(testdl):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            yhat = model(x).to(device)\n",
    "            loss = loss_function(yhat, y)\n",
    "            \n",
    "            # Track train loss\n",
    "            test_loss  = np.concatenate((test_loss, loss.item()), axis=None)\n",
    "            \n",
    "        if verbose:\n",
    "            cur_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'Epoch {epoch+1}: train_loss: {train_loss.mean():.4f} test_loss: {test_loss.mean():.4f}')\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': model,\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'test_loss': test_loss.mean(),\n",
    "            'train_loss': train_loss.mean()\n",
    "        }\n",
    "        path_checkpoint = save_folder + '/nnet_1.pth'\n",
    "        torch.save(checkpoint, path_checkpoint)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Finished training in {time.time() - start_time:.4f} seconds\")\n",
    "        print(f'Model save to {path_checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T06:59:33.549596Z",
     "start_time": "2020-06-13T06:59:29.132406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on:  cpu\n",
      "Epoch 1: train_loss: 0.4709 test_loss: 0.1475\n",
      "Epoch 2: train_loss: 0.1481 test_loss: 0.1371\n",
      "Epoch 3: train_loss: 0.1360 test_loss: 0.1425\n",
      "Epoch 4: train_loss: 0.1363 test_loss: 0.1359\n",
      "Epoch 5: train_loss: 0.1337 test_loss: 0.1364\n",
      "Finished training in 4.4022 seconds\n",
      "Model save to model/nnet_1.pth\n"
     ]
    }
   ],
   "source": [
    "train_loop(traindl, testdl, model, optimizer, loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "man_env",
   "language": "python",
   "name": "man_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
